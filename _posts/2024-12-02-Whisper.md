---
title: Whisper
author: Su
date: 2024-12-02 11:00:00 +0800
categories: [Paper Review]
tags: [Audio]
pin: false
use_math: true
---

[Paper Link](https://arxiv.org/pdf/2212.04356)         [Github Link](https://github.com/openai/whisper)

## 🍏 Key Takeaways
- 1️⃣ 모델 구조가 아닌 데이터의 양과 유형이 더 중요할 수 있다. 본 논문에서는 Plain Transformer 모델에 매우 큰 데이터의 Weakly Supervised 방식으로 학습시켰다. 
- 2️⃣ 학습 데이터 크기가 16배 증가하면 WER이 절반으로 감소하는 경향을 보인다. 
- 3️⃣ Unsupervised Pretrain & Fine-Tuning 구조는 dataset-specific quirks일 확률이 높다. 이를 위해 Fine-Tuning 단계를 없애고 Zero-shot으로만 성능을 측정했다. 

## 1. Previous Unsupervised Pre-training의 문제점
Wav2Vec으로 대표되는 기존의 Unsupervised pre-training은 audio encoder의 품질을 상당하게 올렸지만, decoder가 이를 따라올 수 없었다. 즉, decoder가 text와 audio representation을 매핑할 수 없었다. 따라서 supervised fine-tuning이 필수적이었다. supervised fine-tuning은 label이 있어야 하므로 매우 비싸고, model의 usefulness와 robustness를 저하한다. 즉, 데이터셋이 모델의 성능을 좌지우지(dataset-specific quirks)한다는 것이다. 

저자들을 이를 해결하기 위해 아래 선행 연구들에서 아이디어를 얻었다.

- 대형 unlabeled dataset을 사용하는 Wav2Vec과 달리 소형 labeled dataset을 사용하는 supervised model이 더 높은 성능을 보였다. 
- CV 분야에서 대형 데이터셋으로  weakly supervised learning을 했을 때 robustness와 일반화 성능이 증가했다. 

저자들은 대형 데이터셋으로 weakly supervised learning을 실험하기로 했다.

## 2. Approch
### 2.1 데이터셋 전처리 
저자들은 총 680,000 hours의 초대형 데이터셋을 사용하였다. 이는 Wav2Vec의 60,000 hours를 훌쩍 상회하는 크기이다.
그 중 117,000 hours는 96개의 언어 음성이고, 이를 영어로 번역한 125,000 hours의 데이터도 포함한다. 

기존 연구들에서 자주 쓰인 전처리 방법인 standardization과 ITN(Inverse Text Normalization)을 과감하게 생략했다. 이를 통해 robustness를 증가시킬 수 있다.
대신에 저자들은 Machine-Generated data를 여러 방법으로 필터링하여 제거했다. 대표적인 예로 모두 uppercase 또는 lowercase이거나, 쉼표를 아예 없앤 것이 있다.

### 2.2 Model
이 논문은 모델 구조에 초점을 맞추지 않았다. 단순하게 Transformer 모델을 사용하였다.

### 2.3 Multitask Format
pretraining-zero shot 구조만으로도 오디오 분야의 다양한 task를 지원할 수 있게 고안되었다. 바로 special token을 사용하여 task와 conditioning information을 decoder의 입력에 함께 넣어 주는 것이다. 

![GitHub - openai/whisper: Robust Speech Recognition via Large-Scale Weak  Supervision](https://raw.githubusercontent.com/openai/whisper/main/approach.png)

- `<|nospeech|>` : predict no speech in an audio segment
- `<|transcribe|>` 또는 `<|translate|>` : 어떤 task인지 specific하게 설정해 준다.

여담이지만 위 그림에 한국어가 있어서 너무 반가웠다.

### 2.4 Training Details
다양한 모델 크기로 실험하였다. 적은 수의 epoch만 학습하기 때문에 과적합은 따로 고려하지 않아도 된다. robustness와 generalization을 높이기 위해 data augmentation이나 normalization을 따로 사용하지 않았다. 

## 3. Experiments

### 3.1 Zero-shot Evaluation
open source dataset을 사용하여 zero-shot으로 evaluation하였다. 보통 학습한 모델을 평가할 때는 train과 같은 distribution의 데이터를 사용한다. 하지만 Whisper에서는 여러 언어 관련 데이터셋에서 모델이 robust한지 확인하고자 했다. 

### 3.2 Evaluation Metrics
음성 인식(ASR) 분야에서는 전통적으로 WER(Word Error Rate)가 평가 지표로 사용된다. WER은 string edit-distance기반이다.
WER의 문제점은 변환된 transcipt에서 사람에게는 전혀 문제가 되지 않는 차이도 반영한다는 것이다. 이는 특정 task에서의 데이터 format을 반영하지 않는 Zero-shot 모델에서는 큰 문제가 되므로 저자들은 non-semantic difference를 제외한 WER를 비교하였다. 

### 3.3 English Speech Recognition
저자들은 WER이 학습된 데이터셋에 치중된 평가 지표라 비판한다. 그러면서 인간과 인공지능 모델은 서로 다른 면을 평가받는다는 흥미로운 주장을 제시하였다.
인간은 distribution에 구애 받지 않는다. 즉 인간의 generalization는 분포 밖에서 측정된다. 하지만 모델은 학습 데이터의 distribution에 conditioned된다. 즉, 모델 성능은 distribution 내의 generalization으로 결정된다.

<img width="392" alt="image" src="https://github.com/user-attachments/assets/4ad0b296-e70f-43f4-98f0-a4af4ee24e53">

기존 모델(파란색)과 다르게 Whisper(보라색)은 인간(주황색)과의 격차를 좁혔다. 기존 모델들은 학습한 데이터가 아닌 다른 데이터셋에서는 상당이 높은 WER 값을 보인다. 



### 3.4 Multi-lingual Speech Recognition

<img width="380" alt="image" src="https://github.com/user-attachments/assets/5188cffb-52b4-42f9-86fa-2da00e9067d1">

VoxPopuli 데이터셋에서는 Whisper가 다른 기존 모델들에 비해 더 높은 WER를 보인다. Whisper는 Zero-shot인데 반해 기존 모델들은 Fine-Tuning으로 VoxPopuli 데이터셋 distribution이 대해 학습해씩 때문이다.
다르게 설명하면, 다양한 distribution 을 갖는 audio dataset 에 대해서 speech recognition 을 수행하는 경우에는 fine-tuning 시에 사용한 dataset 에서 검증된 성능보다 실제 성능이 좋지 않을 수 밖에 없는 것이다.

<img width="467" alt="image" src="https://github.com/user-attachments/assets/d342feb0-2512-4647-b985-f1767a6368c2">

pretraining dataset에서 해당 언어의 데이터가 차지하는 양과 그 WER의 상관관계는 $R^2=0.84$로 굉장히 높게 나온다.



## Reference
- 🌟[[openAI] Whisper 논문 리뷰](https://velog.io/@nothh/openAI-Whisper-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0)
- 🌟[[리뷰] Robust Speech Recognition via Large-Scale Weak Supervision](https://cypsw.tistory.com/entry/Robust-Speech-Recognition-via-Large-Scale-Weak-Supervision-%EB%B6%84%EC%84%9D)
- [[논문리뷰] Robust Speech Recognition via Large-Scale Weak Supervision (Whisper)](https://kimjy99.github.io/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/whisper/)

