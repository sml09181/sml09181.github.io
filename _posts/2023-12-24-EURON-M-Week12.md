---
title: Deep Learning Specialization 4-1 | Convolutional Neural Networks
author: Su
date: 2023-12-24 03:55:00 +0800
categories: [DL]
tags: [EURON]
pin: false
use_math: true
---

Learning Source
+ [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning?utm_source=deeplearningai&utm_medium=institutions&utm_campaign=SocialYoutubeDLSC1W1L1#courses)
+ [부스트코스 딥러닝 4단계: 합성곱 신경망 네트워크(CNN)](https://www.boostcourse.org/ai218/lecture/34895)

<br>

## **Computer Vision**
<img width="632" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/a0b5691f-c9be-4228-8177-9c197ee0fab7">

+ 컴퓨터 비전은 얼굴인식, 예술등 다양한 분야에 응용되고 있다. 컴퓨터 비전 알고리즘의 발전은 새로운 비전 관련 어플리케이션을 창출해낼 뿐만 아니라 자연어 처리등 다른 분야에도 영향을 준다.
+ 컴퓨터 비전에서 주로 다루는 문제
  + 이미지분류
  + 객체 인식
  + 신경망 스타일 변형 등<br>

<img width="625" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/3ff794cf-46e6-4b7f-9f96-6292573a49b8">

+ 문제점: 컴퓨터 비전은 input data가 아주 크다. ➡️ 합성곱 연산으로 해결




## **Edge Detection Example**
<img width="630" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/a8fb76be-8fc1-4106-bcfb-82218b23eb92">
  
+ 앞쪽에서는 Low level feature 추출, 뒤로 갈수록 High level feature 추출


+ 이미지: (H x W)로 표현
+ 합성곱 연산 기호
  + <code>*</code> : 합성곱 연산 in 수학
  + <code>ConvForward</code>: 합성곱 연산 in python
  + <code>tf.nn.conv2d</code>: 합성곱 연산 in tensorflow
  + <code>Conv2d</code>: 합성곱 연산 in keras<br>
+ 합성곱 연산 진행 방식
  + 왼쪽 이미지: 원래 이미지
  + 중앙에 있는 3 x 3 행렬: 필터(커널)
  + 각각의 원소곱 후 전부 더해 준다.


<img src="https://github.com/sml09181/sml09181.github.io/assets/105408672/df862cb4-7f88-4830-b241-52d43c31653a">

  + 그 후 다음 스텝으로 필터(커널)을 한 칸 이동하여 합성곱 연산을 진행
  + 이렇게 이미지의 밑부분까지 진행하여 최종 4 x 4 의 새로운 행렬을 만들어 낸다.<br>

<img src="https://github.com/sml09181/sml09181.github.io/assets/105408672/5e7ca740-8f21-4cbf-b0ed-8a6f88575e80">


+ 수직 윤곽선 탐지(수직 경계선을 검출)
  + 아래 그림의 왼쪽 이미지에서 10과 0 사이의 경계선이 수직 윤곽선이다.
  + 필터를 통과해 합성곱 연산을 하게 되면 밝은 부분이 중앙으로 나타난다. ➡️ 원래 이미지의 경계선에 해당하는 부분
  + 비록 크기가 안맞고 검출된 경계선이 조금은 두껍지만 이는 원래 이미지가 작아서 그렇다.<br>

<img src="https://github.com/sml09181/sml09181.github.io/assets/105408672/f1d151ab-07a2-4926-a163-2b16768aa939">



## **More Edge Detection**
<img src="https://github.com/sml09181/sml09181.github.io/assets/105408672/fc830881-3e9c-4630-a587-c8f3f12156e2">

+ 윤곽선을 탐지하려고 사람들이 연구한 Sobel 필터, Scharr 필터 등이 있다.
+ 다양한 필터가 있지만, 최근 딥러닝에서는 임의의 숫자로 만든 다음에 역전파를 통해 알아서 학습시켜서 문제에 적합한 필터를 만드는 방법 사용
+ 필터를 학습시킬 수도 있다.
+ 9개의 숫자를 변수로 두고 데이터로부터 학습하게 함으로써 좀 더 강력한 하위 특징을 잡아낼 수 있게 한다.


## **Padding**
+ 기존 방법의 2가지 단점
  + 1️⃣ 계속 합성곱 연산을 학하게 되면, 이미지가 계속 축소 됩니다.
  + 2️⃣ 가장자리 픽셀은 단 한 번만 사용된다. 즉, 덜 사용됨으로서 이미지 윤곽쪽의 정보를 버리게 된다.
+ 해결 방법: <code>Padding</code>
  + 이미지 주위에 추가로 하나의 경계를 덧대는 것
  + 그러므로 인해서 이미지 크기가 조금 커집니다. 보통 숫자 0을 사용<br>

<img width="631" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/6495f7c1-1011-41b9-a5d2-7208cc16825f">


+ 최종 이미지 크기: $(n + 2p - f + 1) x (n + 2p - f + 1)$
  + $n$: 이미지 크기
  + $p$: 패딩 크기
  + $f$: 필터 크기
+ 일반적인 필터 크기 ➡️ **홀수**!!
  + 이유 1️⃣: 비대칭으로 padding 해줘야 한다.
    + 홀수일 때는 합성곱에서 동일한 크기로 패딩을 더해줄 수 있다.
    + 하지만 짝수면 왼쪽과 오른쪽을 다르게 패딩해야하기 때문에 번거롭다.
  + 이유 2️⃣: 중심위치(중심 픽셀)가 존재합니다.
+ Valid and Same convolutions
  + **Valid**: no padding
  + **Same**: Pad so that output size is the same as the input size.<br>
<img width="629" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/a795aaa0-0e6a-4a41-be6c-3e76127bd587">



## **Strided Convolutions**
+ <code>Stride</code>: 필터의 이동 횟수
  + 기존에 필터를 한 칸씩 이동시켜 계산했다면, 스트라이드를 주게 되면 그 수만큼 이동시켜 계산하게 된다.
+ 최종 크기: $(\frac{n+2p-f}{s}+1) \times (\frac{n+2p-f}{s}+1)$
  + 만약에 정수가 아니라면 내림(floor)한다. 
  + 보통은 필터에 맞춰서 최대한 크기가 정수가 될수 있도록 패딩과 스트라이드 수치를 맞춘다.
  + 필터가 패딩을 더한 이미지 안에서 가득 차있을 때만 계산하고, 일부분이 밖으로 빠져나와 있다면 안 해주게 된다.<br>

<img width="626" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/3567b77a-56e4-47c5-945c-585f947cdcf2">


+ 교차상관과 합성곱의 관계 in 신호 처리
  + 일반적으로 수학에서 정의하는 합성곱은 합성곱을 하기 전에 필터를 가로축과 세로축으로 뒤집는 연산을 해줘야 한다.
  + 지금까지 배운 합성곱은 사실 교차상관이지만 딥러닝에서는 관습적으로 합성곱이라고 한다. 
  + 딥러닝에서는 뒤집는 연산(미러링 과정)을 생략한다.
    + 뒤집는 과정은 신호처리에서는 결합 법칙이 성립하게 해주기 때문에 유용하지만, 심층 신경망 분야에서는 아무런 영향이 없기 때문에 생략하게 된다.<br>
<img width="629" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/92fe64bb-ad5b-465d-9627-95f3c15b98a7">


## **Convolutions Over Volumns**
+ 이미지에 색상(RGB)이 들어가면 입체형으로 변하게 되며, 차원이 하나 증가한다.
+ Input Image Shape: (H x W x C) 
  + 채널(C): 색상 또는 입체형 이미지의 깊이
+ 이에 따라 합성곱에 사용되는 하나의 필터도 각 채널별로 하나씩 증가하게 된다.<br>
<img src="https://github.com/sml09181/sml09181.github.io/assets/105408672/cb8a8e6d-82ce-4622-bf3f-a949e5dc68c3">

+ 입체 이미지의 합성곱 계산은 모든 채널의 합성곱 연산을 더해주는 형식으로 위 그림과 같다.
+ 각 채널 별로 필터는 모두 같은 것을 사용할 수도 있고 다른 것을 사용할 수도 있다.
+ 패딩과 스트라이드가 없다고 가정했을 때
  + 최종 출력:  $(n \times n \times n_c) \times (f \times f \times n_c) = ( n-f+1) \times (n-f+1) \times n_{\prime n}$
  + $n$: 이미지의 크기
  + $n_c$: 채널의 개수
  + $f$: 필터의 크기
  + $n_{\prime c}$: 사용된 필터의 개수

## **One layer of a convolutional network**
+ 합성곱 신경망의 한 계층의 구성
  + 합성곱 연산 ➡️ 편향 추가 ➡️ 활성화 함수
  + 활성화 함수
    + 비선형성을 적용하기 위함
    + 보통 ReLU를 많이 사용
+ 표기법 재정리
  + $l$: $l$번째 계층
  + $f^{[l]}$: 필터의 크기
  + $p^{[l]}$: 패딩의 양
  + $s^{[l]}$: 스트라이드 크기
  + $n_H$: 이미지의 높이
  + $n_W$: 이미지의 넓이
  + $n_c$: 채널의 수
+ 다음 연산이 $l$ 번째 층의 연산이면, 이전 층 $(l-1)$의 이미지의 크기는 $n_H^{[l-1]} \times n_W^{[l-1]} \times n_c^{[l-1]}$ 가 된다.
  + 그 결과로 나오는 이미지의 크기는 $n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]}$
  + $l$ 번째 층의 높이 혹은 넓이의 크기연산 공식은 아래와 같다.
  + $n_H^{[l]} = \frac{n_H^{[l-1]} + 2p^{[l]}-f^{[l]}}{s^{[l]}} + 1$ 
  + $n_W^{[l]} = \frac{n_W^{[l-1]} + 2p^{[l]}-f^{[l]}}{s^{[l]}} + 1$ 
+ $n_c^{[l]}$ 개의 크기가 $f^{[l]} \times f^{[l]} \times n_c^{[l-1]}$ 인 필터가 합성곱 연산을 진행하게 된다. 그리고 활성화 함수를 거쳐 $l$ 번째 층의 결과값이 계산된다. 합성곱 연산에 사용된 변수는 총 $f^{[l]} \times f^{[l]} \times n_c^{[l-1]} \times n_c^{[l]} $ 개이다.
+ 기존의 단순 신경망을 사용한다면 가중치 행렬 $W^{[l]}$ 의 크기 $(n_H^{[l-1]} \times n_W^{[l-1]} \times n_c^{[l-1]}) \times (n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]}) $ 인데, 이보다 더 적은 변수로 계산이 가능해졌다.
  + 예를 들어 28 x 28 x 3 이미지를 동일한 5 x 5 필터 20개를 사용해서 계산(패딩없고 스트라이드는 1) 한다면, 24 x 24 x 20 크기의 결과가 나온다.
  + 합성곱 연산에 필요한 총 변수의 크기는 5 x 5 x 3 x 20 + 20 = 1520 이지만, 단순 신경망을 사용하여 같은 크기의 결과를 나타내려면 (28 x 28 x 3) x (24 x 24 x 20) + (24 x 24 x 20) = 27,106,560 만큼의 변수가 필요하다.
  + 2개의 채널로 이루어진 이미지를 5x5 필터 6개를 통해 28x28x6의 이미지로 합성곱 연산하는 경우, 306개의 변수가 필요하다.
  + 이때 입력 이미지 크기가 아무리 커져도 파라미터 수는 고정된다.
    + overfitting 방지
    + feature 추출기의 역할 적절히 수행
  + 필터마다 하나의 편향값을 가진다.


## **A simple convolution network example**
+ 아래 그림은 강의에서 나온 간단한 합성곱 신경망 예시이다.<br>
<img src="https://github.com/sml09181/sml09181.github.io/assets/105408672/5a2f2d87-9eb0-4b64-a061-ddaebd5b780a">

+ 합성곱 신경망의 크기는 깊어질수록 점점 줄어든다.
+ 대부분의 신경망은 합성곱 층, 풀링 층, 완전 연결 층으로 구성되어 있다.
+ CNN Structure
<br>
<img src="https://github.com/sml09181/sml09181.github.io/assets/105408672/4dfe9876-6ea5-4d44-8240-f6710c63383c">

## **Pooling Layers**
+ 합성곱 신경망에서는 풀링 층을 사용해 표현의 크기를 줄임으로써 계산속도를 줄이고 특징을 더 잘 검출 해낼 수 있다.
+ 각 채널에 독립적으로 적용한다.
+ 종류(보통 Max Pooling 사용)
  + Max Pooling
  + Average Pooling
<br>
  
<img src="https://github.com/sml09181/sml09181.github.io/assets/105408672/08527fbc-5070-43bd-95bb-2ff4d00b1a6f">

+ Max Pooling
  + 이미지의 특징이 펄터의 한 부분에서 검출되면 높은 수를 남기고 그렇지 않으면 다른 최대값들에 비해 상대적으로 작아져, 특징을 더 잘 남긴다.
+ 위 예시의 최대 풀링은 필터 크기가 2, 스트라이드가 2, 패딩이 없는 필터를 합성곱 연산이 아닌 최대 연산을 하는 것과 같다.
  + 이전 강의에서 이야기한 공식이 풀링 층에서도 적용된다
  + 4 x 4 이미지의 출력 결과는 2 x 2 가 됩니다.
  + 결과의 크기: $\frac{4+2\times 0 -2}{2} +1 = 2  $
  + 주로 f=2, s=2를 많이 쓰는데 높이와 너비를 절반으로 줄여 주는 효과가 있다.
  + 최대 풀링에서는 패딩을 거의 사용하지 않는다. but 예외 존재
+ 파라미터가 없기 때문에 역전파X

## **Convolutional neural network example**
+ LeNet-5 살펴 보기<br>

<img src="https://github.com/sml09181/sml09181.github.io/assets/105408672/556bc6ea-d5c7-4588-a5fa-d7c57b8e6148">

+ 합성곱 신경망의 분야에서는 두 종류의 관습이 있는데, 
  + 하나는 합성곱 층과 풀링 층을 하나의 층으로 보고,
  + 다른 하나는 합성곱 층과 풀링 층을 각각의 층으로 간주하는 것
+ 여기서는 전자의 방법을 사용
    + 풀링 층에 학습 해야 할 변수가 없기 때문에 합성곱 층과 풀링 층을 하나로 간주
    + 가중치가 있는 층만 Layer로 간주<br>

<img width="300" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/3fa51e87-831d-498f-91d6-6f2f7c9530ee">

+ Neural Network Example<br>
<img width="517" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/50d720ac-83a1-4b10-900c-7ed7280daaf9">

  + 합성곱 층이 상대적으로 적은 변수를 가진다.
  + 신경망의 대부분의 변수는 FC Layer에 있다.
  + 활성값의 크기도 신경망이 깊어질수록 점점 감소한다.

## **Why Convolutions?**
<img width="626" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/f798c876-8629-4950-9042-9ea30757cc63">

+ 합성곱 신경망을 사용하면 변수를 적게 사용할 수 있다.
  + 예를 들어, 32 x 32 x 3 이미지를 5 x 5 필터 6개를 통해 28 x 28 x 6 의 이미지로 합성곱 연산을 했을 경우, 필요한 변수의 개수는 5 x 5 x 3 x 6 + 6 = 456, 하지만 일반적인 신경망으로는 3,072 x 4,704 + 4,704, 약 1400 만개의 변수가 필요합니다.<br>

<img width="630" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/85d65218-ae15-4fb8-a252-bd5859b413a9">

+ Why convolutions
  + 1️⃣ parameter sharing(변수 공유)
    + 어떤 한 부분에서 이미지의 특성을 검출하는 필터가 이미지의 다른 부분에서도 똑같이 적용되거나 도움이 된다.
    + high level feature와 low level feature 모두 동일
  + 2️⃣ sparsity of connections(희소 연결)
    + 출력값이 이미지의 일부(작은 입력값)에만 영향을 받고 나머지 픽셀들의 영향을 받지 않기 때문에 과대적합을 방지할 수 있다.
    + 
+ 합성곱 신경망은 이동 불변성(translation invariance)을 포착하는데도 용이
  + 이미지가 약간의 변형이 있어도 이를 포착할 수 있다.<br>
<img width="628" alt="image" src="https://github.com/sml09181/sml09181.github.io/assets/105408672/e9530578-af0d-4c20-aacb-351243a889db">

<br>
<br>
Source:<br>
[CNN Structure Image](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)