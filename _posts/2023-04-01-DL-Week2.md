---
title: Deep Learning Week2 - Regression and Classification
author:
    name: Sujin Kim
date: 2023-04-01 03:55:00 +0800
categories: [MLDL]
tags: [ECC, DL]
pin: false
use_math: true
---

# Overview

**for classification:**
- Linear Statistical Model
- Logistic Regression
- Naive Bayes
- Decision Tree
- Random Forest


**for regression:**
- Decision Tree
- Random Forest

> log-odds를 regression한다고 하셨는데, 무슨 뜻인지 잘 모르겠다.
{: .prompt-warning }

# 2.1 Linear Statistical Model
1. Linear Function
    ex: $$ E(Y) = {\beta}_0 + {\beta}_1x $$
    - linear function of $x$
    - linear function of  ${\beta}_0$ and ${\beta}_1$<BR>
    ex: $$ E(Y) = {\beta}_0 + {\beta}_1x^2 $$
    - NOT a linear function of $x$
    - linear function of  ${\beta}_0$ and ${\beta}_1$<br>
=> Linear statistical model for Y
    - linear function of  ${\beta}_0$ and ${\beta}_1$<BR>
    - BUT, 꼭 linear function of $x$일 필요는 없음
    - 즉, $Y = {\beta}_0 + {\beta}_1(lnx) + \epsilon$도 Linear model이다.
    - 우리가 관심 있는 변수인 $\beta$에 대해 선형이다.

2. Linear Statistical model:
$$Y = {\beta}_0 + {\beta}_1x_1 + {\beta}_2x_2 + ... + {\beta}_kx_k+\epsilon$$
- $x_1, ..., x_k$: a set of independent variables(=input variable, features)
- $Y$: a response(=dependent variable)
- ${\beta}_0 +...+{\beta}_k$: unknown parameters
- $\epsilon$: a random variable -> 주로 가우시안 분포를 따른다고 가정

3. SSE
$E(\epsilon) = 0$이라 가정하고, 


# 2.2 Gradient Descent
# 2-3. Logistic Regression#

# 2-4. Decision Tree 

# 2-5. Random Forest

Reference:
- [Log Odds Ratio](https://blog.naver.com/sw4r/221150181217)